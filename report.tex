\documentclass[12pt]{report}
\linespread{2}
\usepackage[pdftex]{graphicx}   
\usepackage{amssymb}
\usepackage{tocbibind}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{natbib}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{stackengine}
\usepackage{subcaption}
\usepackage[margin=1.25in]{geometry}
\usepackage[nodayofweek]{datetime}
\newdateformat{mydate}{{ }\shortmonthname[\THEMONTH], \THEYEAR}

\newdateformat{myyear}{{ }\THEYEAR}
% latex
% \usepackage[hidelinks]{hyperref}
\usepackage{hyperref}
\usepackage[hyphenbreaks]{breakurl}

\usepackage{booktabs}
%\usepackage{lineno}
%\linenumbers
\usepackage{calc}  
\usepackage{enumitem}  
%\usepackage{sectsty}
%
%%\chapternumberfont{\tiny} 
%\chaptertitlefont{\huge}

%opening
\title{Improving Neural Machine Translation for Morphologically rich languages }
\author{Raja Gunasekaran}

\usepackage{graphicx}
\usepackage{pdfpages}
\graphicspath{ {images/} }

\begin{document}


\pagenumbering{roman}
%\thispagestyle{empty} %remove page number from title page
\includepdf{tex/title.pdf}
	
%\setcounter{page}{2} % Title Page gets number "i"
%\thispagestyle{empty} %remove page number from title page	
%\input{tex/title.tex}
\pagestyle{plain}
\clearpage
\input{tex/abstract.tex}
\phantomsection\addcontentsline{toc}{chapter}{Abstract}
\tableofcontents
\listoftables
\listoffigures
\newpage
\pagenumbering{arabic}


%\addcontentsline{toc}{chapter}{\abstractname}
%\begin{abstract}	
%\end{abstract}
%\cleardoublepage
%\listoffigures
%\cleardoublepage
%\addcontentsline{toc}{chapter}{\listfigurename}
%\listoftables
%\cleardoublepage
%\addcontentsline{toc}{chapter}{\listtablename}

\chapter{Introduction}
\input{tex/intro.tex}

\chapter{Background}
\label{background}
\input{tex/background.tex}

\chapter{Handling Rare and Unknown Words}
\label{related}
\input{tex/related.tex}

\chapter{Vocabulary Expansion for NMT}
\label{proposed}
\input{tex/proposed.tex}


\chapter{Vector Representations for OOV words}
\label{comparision1}
\input{tex/experiment1.tex}

\chapter{MT for Morphologically Rich Languages}
\label{experiments}
\input{tex/experiment2.tex}

\chapter{Conclusion and Future Work}
\label{conclusion}
\input{tex/conclusion.tex}

%\input{tex/timeline.tex}

\newpage
\appendix
\chapter{List of Abbreviations and Definitions}

\begin{description}[leftmargin=!,labelwidth=\widthof{\bfseries The longest label}]
	\item[BLEU] Bilingual Evaluation Understudy
	\item[BPE] Byte Pair Encoding
	\item[CNN] Convolution Neural Network
	\item[GRU] Gated Recurrent Unit
	\item[LSTM] Long Short-Term Memory
	\item[MT] Machine Translation
	\item[NMT] Neural Machine Translation
	\item[OOV]  Out Of Vocabulary words
	\item[RNN] Recurrent Neural Network
	\item[SMT] Statistical Machine Translation
	\item[Morpheme] The smallest meaningful units in a language.
	\item[Word embedding] A technique used to map and represent words in a language as vectors of real number, where words with similar meaning have similar representations.
	\item[Word vector] A vector used to represent a word in the vector space. Also known as \textit{Word representations}
	\item[Morphological rich languages] Languages that encode large amount of information through morphology. They have a very large vocabulary size since there can large number of word forms per lexeme.
\end{description}


% SUmmarize key points. less emphasis on technical grounds. Put in exact technical content.

\bibliography{bib}
\bibliographystyle{apalike}


\end{document}
